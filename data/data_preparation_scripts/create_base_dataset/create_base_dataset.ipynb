{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pymatgen.core import Structure\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "from mp_api.client import MPRester\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import matplotlib.colors as mcolors\n",
    "import traceback\n",
    "import orjson\n",
    "import zipfile\n",
    "import zstandard as zstd\n",
    "import shutil\n",
    "from pymatgen.symmetry.analyzer import SpacegroupAnalyzer\n",
    "from PIL import Image\n",
    "from ase.visualize import view\n",
    "from ase.io import write\n",
    "from ase.io.utils import PlottingVariables # write kwargs here\n",
    "import itertools\n",
    "from pymatgen.analysis.structure_matcher import StructureMatcher\n",
    "from typing import Callable\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "colors = list(mcolors.TABLEAU_COLORS)\n",
    "sys.path.append(\"../../../\")\n",
    "from utils.save_and_load import save_to_json, load_from_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor to scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict2tensor(data: dict):\n",
    "    d = {k: v[\"value\"] for k, v in data[\"dinf\"].items()}\n",
    "    return np.array(\n",
    "        [\n",
    "            [\n",
    "                [d[\"111\"], d[\"112\"], d[\"113\"]],\n",
    "                [d[\"121\"], d[\"122\"], d[\"123\"]],\n",
    "                [d[\"131\"], d[\"132\"], d[\"133\"]],\n",
    "            ],\n",
    "            [\n",
    "                [d[\"211\"], d[\"212\"], d[\"213\"]],\n",
    "                [d[\"221\"], d[\"222\"], d[\"223\"]],\n",
    "                [d[\"231\"], d[\"232\"], d[\"233\"]],\n",
    "            ],\n",
    "            [\n",
    "                [d[\"311\"], d[\"312\"], d[\"313\"]],\n",
    "                [d[\"321\"], d[\"322\"], d[\"323\"]],\n",
    "                [d[\"331\"], d[\"332\"], d[\"333\"]],\n",
    "            ],\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor2scalar(d: np.ndarray):\n",
    "    return (\n",
    "        19 / 105 * sum(d[i, i, i] ** 2 for i in range(3))\n",
    "        + 13\n",
    "        / 105\n",
    "        * sum(d[i, i, i] * d[i, j, j] for i in range(3) for j in range(3) if i != j)\n",
    "        + 44 / 105 * sum(d[i, i, j] ** 2 for i in range(3) for j in range(3) if i != j)\n",
    "        + 13\n",
    "        / 105\n",
    "        * sum(d[a, a, b] * d[b, c, c] for a, b, c in ((0, 1, 2), (1, 2, 0), (2, 0, 1)))\n",
    "        + 5\n",
    "        / 7\n",
    "        * np.mean(\n",
    "            [\n",
    "                d[i, j, k] ** 2\n",
    "                for i in range(3)\n",
    "                for j in range(3)\n",
    "                for k in range(3)\n",
    "                if i != j and j != k and k != i\n",
    "            ]\n",
    "        )\n",
    "    ) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levine, Z. H.; Allan, D. C. Large Local-Field Effects in the Second-Harmonic Susceptibility of Crystalline Urea. Phys. Rev. B 1993, 48, 7783.\n",
    "\n",
    "urea_dict = {\n",
    "    \"dinf\": {\n",
    "        \"111\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"112\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"113\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"121\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"122\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"123\": {\"value\": 1.2, \"unit\": \"pm/V\"},\n",
    "        \"131\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"132\": {\"value\": 1.2, \"unit\": \"pm/V\"},\n",
    "        \"133\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"211\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"212\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"213\": {\"value\": 1.2, \"unit\": \"pm/V\"},\n",
    "        \"221\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"222\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"223\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"231\": {\"value\": 1.2, \"unit\": \"pm/V\"},\n",
    "        \"232\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"233\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"311\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"312\": {\"value\": 1.2, \"unit\": \"pm/V\"},\n",
    "        \"313\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"321\": {\"value\": 1.2, \"unit\": \"pm/V\"},\n",
    "        \"322\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"323\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"331\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"332\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"333\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d0ra03136d.pdf, 252.pdf\n",
    "KDP_dict = {\n",
    "    \"dinf\": {\n",
    "        \"111\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"112\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"113\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"121\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"122\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"123\": {\"value\": 0.41, \"unit\": \"pm/V\"},\n",
    "        \"131\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"132\": {\"value\": 0.41, \"unit\": \"pm/V\"},\n",
    "        \"133\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"211\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"212\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"213\": {\"value\": 0.41, \"unit\": \"pm/V\"},\n",
    "        \"221\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"222\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"223\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"231\": {\"value\": 0.41, \"unit\": \"pm/V\"},\n",
    "        \"232\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"233\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"311\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"312\": {\"value\": 0.41, \"unit\": \"pm/V\"},\n",
    "        \"313\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"321\": {\"value\": 0.41, \"unit\": \"pm/V\"},\n",
    "        \"322\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"323\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"331\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"332\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "        \"333\": {\"value\": 0, \"unit\": \"pm/V\"},\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KDP_eff = tensor2scalar(dict2tensor(KDP_dict))\n",
    "KDP_eff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urea = tensor2scalar(dict2tensor(urea_dict))\n",
    "urea_div_KDP = urea / KDP_eff\n",
    "urea, urea_div_KDP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Articles data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles\n",
    "path1 = Path(\n",
    "    \"../../raw_data/private/Metal–organic frameworks as competitive (1)/Metal–organic frameworks as competitive/\"\n",
    ")\n",
    "path2 = Path(\n",
    "    \"../../raw_data/private/Rational_Synthesis_of_Noncentrosymmetric_Metal–Organic_Frameworks/Rational Synthesis of Noncentrosymmetric Metal–Organic Frameworks for Second-Order Nonlinear Optics/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1: list[tuple[str, float]] = [\n",
    "    (\"KDP\", 2.5),\n",
    "    (\"urea\", 80),\n",
    "    (\"KDP\", 0.1),\n",
    "    (\"KDP\", 0.13),\n",
    "    (\"SiO2\", 80),\n",
    "    (\"KDP\", 5),\n",
    "    (\"urea\", 0.8),\n",
    "    (\"urea\", 1),\n",
    "    (\"SiO2\", 15),\n",
    "    (\"KDP\", 2.1),\n",
    "    (\"urea\", 0.5),\n",
    "    (\"urea\", 0.5),\n",
    "    (\"urea\", 0.3),\n",
    "    (\"urea\", 0.3),\n",
    "    (\"urea\", 0.3),\n",
    "    (\"urea\", 0.7),\n",
    "    (\"KDP\", 4.24),\n",
    "    (\"KDP\", 0.9),\n",
    "    (\"KDP\", 0.1),\n",
    "    (\"KDP\", 0.5),\n",
    "    (\"urea\", 0.8),\n",
    "    (\"KDP\", 4),\n",
    "    (\"KDP\", 7),\n",
    "    (\"urea\", 0.5),\n",
    "    (\"urea\", 1.5),\n",
    "    (\"KDP\", 1.5),\n",
    "    (\"urea\", 0.9),\n",
    "    (\"KDP\", 0.35),\n",
    "    (\"KDP\", 0.40),\n",
    "    (\"KDP\", 0.17),\n",
    "    (\"KDP\", 0.08),\n",
    "    (\"KDP\", 0.10),\n",
    "    (\"urea\", 0.3),\n",
    "    (\"urea\", 0.4),\n",
    "    (\"urea\", 0.4),\n",
    "    (\"urea\", 0.8),\n",
    "    (\"KDP\", 3.6),\n",
    "    (\"urea\", 0.7),\n",
    "    (\"urea\", 0.7),\n",
    "    (\"urea\", 0.8),\n",
    "    (\"KDP\", 1),\n",
    "    (\"KDP\", 1.1),\n",
    "    (\"KDP\", 15),\n",
    "    (\"KDP\", 0.27),\n",
    "    (\"urea\", 0.3),\n",
    "    (\"KDP\", 0.7),\n",
    "    (\"KDP\", 0.466),\n",
    "    (\"KDP\", 0.122),\n",
    "    (\"KDP\", 5.6),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2: list[tuple[int | str, str | None, float | None]] = [\n",
    "    (1, \"SiO2\", 1.5),\n",
    "    (4, \"SiO2\", 126),\n",
    "    (6, \"SiO2\", 18),\n",
    "    (8, \"SiO2\", 310),\n",
    "    (9, \"SiO2\", 400),\n",
    "    (10, \"SiO2\", 345),\n",
    "    (11, \"KDP\", 3),\n",
    "    (12, \"KDP\", 5),\n",
    "    (13, \"urea\", 0.5),\n",
    "    (14, None, None),  # active\n",
    "    (15, \"urea\", 1.2),\n",
    "    (16, \"urea\", 1),\n",
    "    (17, \"urea\", 4),\n",
    "    (18, \"urea\", 0.4),\n",
    "    (19, \"KDP\", 0.5),\n",
    "    (20, \"KDP\", 1.1),\n",
    "    (21, \"KDP\", 2.5),\n",
    "    (22, \"SiO2\", 80),\n",
    "    (23, \"SiO2\", 10),\n",
    "    (24, \"SiO2\", 70),\n",
    "    (25, \"KDP\", 5),\n",
    "    (26, \"KDP\", 1),\n",
    "    (27, \"KDP\", 1),  # > 1\n",
    "    (28, \"KDP\", 3.5),\n",
    "    (29, \"KDP\", 5),\n",
    "    (30, \"KDP\", 6.5),\n",
    "    (31, \"urea\", 0.5),\n",
    "    (32, \"KDP\", 0.4),\n",
    "    (33, \"KDP\", 0.2),\n",
    "    (34, \"urea\", 0.7),\n",
    "    (35, \"urea\", 0.7),\n",
    "    (36, \"KDP\", 3),\n",
    "    (37, \"KDP\", 2),\n",
    "    (38, \"urea\", 0.6),\n",
    "    (39, \"urea\", 0.7),\n",
    "    (40, \"urea\", 0.8),\n",
    "    (41, \"KDP\", 4),\n",
    "    (42, \"urea\", 0.8),\n",
    "    (43, \"KDP\", 2.5),\n",
    "    (44, None, None),  # active\n",
    "    (45, \"KDP\", 3.5),  # 3-4\n",
    "    (46, \"KDP\", 1.5),\n",
    "    (47, \"KDP\", 2.3),\n",
    "    (48, \"KDP\", 0.6),\n",
    "    (49, None, None),  # active\n",
    "    (50, \"KDP\", 10),\n",
    "    (\"51a\", \"SiO2\", 150),  # ???\n",
    "    (\"51b\", \"SiO2\", 155),\n",
    "    (\"51c\", \"SiO2\", 90),\n",
    "    (\"51d\", \"SiO2\", 110),\n",
    "    (\"52a\", \"SiO2\", 15),\n",
    "    (\"52b\", \"SiO2\", 24),\n",
    "    (\"52c\", \"SiO2\", 35),\n",
    "    (\"52d\", \"SiO2\", 11),\n",
    "    (\"52e\", \"SiO2\", 20),\n",
    "    (\"52f\", \"SiO2\", 17),  # .\n",
    "    (53, \"SiO2\", 2),\n",
    "    (54, \"SiO2\", 1000),\n",
    "    (56, \"SiO2\", 400),  # !\n",
    "    (57, None, None),  # large\n",
    "    (58, \"urea\", 50),\n",
    "    (59, \"urea\", 0.4),\n",
    "    (60, \"urea\", 16.8),\n",
    "    (61, \"KDP\", 8),\n",
    "    (62, \"KDP\", 2),\n",
    "    (63, \"urea\", 0.5),\n",
    "    (64, \"urea\", 0.02),\n",
    "    (65, \"urea\", 0.9),\n",
    "    (66, \"KDP\", 1),\n",
    "    (67, \"KDP\", 2),\n",
    "    (68, \"urea\", 1),\n",
    "    (69, None, None),  # active\n",
    "    (70, \"SiO2\", 75),\n",
    "    (71, \"urea\", 1),\n",
    "    (72, \"KDP\", 2),\n",
    "    (73, \"urea\", 0.7),\n",
    "    (74, None, None),  # active\n",
    "    (75, \"urea\", 0.8),\n",
    "    (76, \"KDP\", 0.4),\n",
    "    (77, \"KDP\", 0.5),\n",
    "    (78, \"KDP\", 1),\n",
    "    (79, \"KDP\", 2),\n",
    "    (80, \"KDP\", 1),  # <1\n",
    "    (81, \"KDP\", 3),\n",
    "    (82, \"KDP\", 1),  # <1\n",
    "    (83, \"urea\", 0.7),\n",
    "    (84, \"urea\", 0.3),\n",
    "    (85, \"SiO2\", 200),  #!\n",
    "    (87, None, None),  # weak\n",
    "    (88, None, None),  # weak\n",
    "    (89, None, None),  # weak\n",
    "    (90, None, None),  # weak\n",
    "    (91, None, None),  # None\n",
    "    (92, \"urea\", 0.3),\n",
    "    (93, \"urea\", 0.6),\n",
    "    (94, \"urea\", 0.8),\n",
    "    (95, \"urea\", 0.8),\n",
    "    (96, \"urea\", 0.8),\n",
    "    (97, \"KDP\", 5),\n",
    "    (98, \"KDP\", 1.5),\n",
    "    (99, None, None),  # active\n",
    "    (100, \"SiO2\", 6),\n",
    "    (101, \"SiO2\", 20),\n",
    "    (102, None, None),  # active\n",
    "    (103, None, None),  # active\n",
    "    (104, None, None),  # active\n",
    "    (105, \"KDP\", 3),\n",
    "    (106, \"KDP\", 1),  # <1\n",
    "    (107, \"urea\", 1),\n",
    "    (108, \"SiO2\", 460),\n",
    "    (109, \"KDP\", 6),\n",
    "    (110, \"KDP\", 1.5),\n",
    "    (111, \"KDP\", 0.2),\n",
    "    (112, \"urea\", 0.3),\n",
    "    (113, \"KDP\", 4),\n",
    "    (114, \"urea\", 2.9),\n",
    "    (115, \"urea\", 0.2),\n",
    "    (116, \"urea\", 0.6),\n",
    "    (117, \"KDP\", 0.8),\n",
    "    (118, \"KDP\", 0.9),\n",
    "    (119, \"urea\", 0.3),\n",
    "    (120, \"urea\", 0.8),\n",
    "    (121, \"urea\", 0.4),\n",
    "    (122, \"KDP\", 2.8),\n",
    "    (123, \"KDP\", 2.6),\n",
    "    (124, None, None),  # active\n",
    "    (125, \"urea\", 0.05),\n",
    "    (126, \"urea\", 0.06),\n",
    "    (127, \"urea\", 1.2),\n",
    "    (128, \"urea\", 0.1),\n",
    "    (129, \"urea\", 1),\n",
    "    (130, \"urea\", 6),\n",
    "    (131, \"urea\", 5),\n",
    "    (132, \"KDP\", 0.8),\n",
    "    (133, \"KDP\", 20),\n",
    "    (134, None, None),  # active\n",
    "    (135, None, None),  # active\n",
    "    (136, \"urea\", 80),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(data1))\n",
    "print(len(data2))\n",
    "print(len(data1) + len(data2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(data1[0]) == 2:\n",
    "    data1 = [(idx, pair[0], pair[1]) for idx, pair in enumerate(data1, 1)]\n",
    "\n",
    "print(data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"error\")\n",
    "\n",
    "cifs1: dict[str, dict] = dict()\n",
    "cifs2: dict[str, dict] = dict()\n",
    "skipped_sio2 = 0\n",
    "skipped_other_reason = 0\n",
    "warnings_count = 0\n",
    "for a, (cifs, path, data) in enumerate(((cifs1, path1, data1), (cifs2, path2, data2))):\n",
    "    # iterate over existing .cif files\n",
    "    for file in os.listdir(path):\n",
    "        try:\n",
    "            i = file.split(\"(\")[1].split(\")\")[0]\n",
    "            cif_name = file.split(\") \")[1]\n",
    "\n",
    "            # skip non-integer idx\n",
    "            try:\n",
    "                int(i)\n",
    "            except Exception:\n",
    "                skipped_sio2 += 1\n",
    "                continue\n",
    "\n",
    "            per_article_cif_idx = int(i)\n",
    "            try:\n",
    "                data_tuple = None\n",
    "                # find corresponding manually copied data entry\n",
    "                for (\n",
    "                    per_article_data_idx,\n",
    "                    reference_structure,\n",
    "                    relative_intensity,\n",
    "                ) in data:\n",
    "                    if per_article_data_idx == per_article_cif_idx:\n",
    "                        data_tuple = (\n",
    "                            per_article_data_idx,\n",
    "                            reference_structure,\n",
    "                            relative_intensity,\n",
    "                        )\n",
    "                if data_tuple is None:\n",
    "                    print(f\"{per_article_cif_idx=} not found\")\n",
    "                    continue\n",
    "                per_article_data_idx, reference_structure, relative_intensity = (\n",
    "                    data_tuple\n",
    "                )\n",
    "                # shg = (\n",
    "                #      reference_intensity ** 0.5 * KDP_eff\n",
    "                #     if data_tuple[-2] == \"KDP\"\n",
    "                #     else data_tuple[-1] ** 0.5 * urea if data_tuple[-2] == \"urea\" else None\n",
    "                # )\n",
    "\n",
    "                # calculating shg scalar by the eq:\n",
    "                # d^2_{MOF} = d^2_{ref} * I_{MOF} / I_{ref}\n",
    "\n",
    "                # d_{KP} ~= d_{MOF} = (d^2_{ref} * I_{MOF} / I_{ref}) ** 0.5\n",
    "                if reference_structure == \"KDP\":\n",
    "                    reference_d_KP = KDP_eff\n",
    "                elif reference_structure == \"urea\":\n",
    "                    reference_d_KP = urea\n",
    "                elif reference_structure == \"SiO2\":\n",
    "                    skipped_sio2 += 1\n",
    "                    continue\n",
    "                else:\n",
    "                    skipped_other_reason += 1\n",
    "                    continue\n",
    "                shg = ((reference_d_KP**2) * relative_intensity) ** 0.5\n",
    "\n",
    "                try:\n",
    "                    structure = Structure.from_file(path.joinpath(file)).as_dict()\n",
    "                except Exception:\n",
    "                    warnings_count += 1\n",
    "                    print(\n",
    "                        [\n",
    "                            line\n",
    "                            for line in traceback.format_exc().split(\"\\n\")\n",
    "                            if \"UserWarning\" in line\n",
    "                        ][0]\n",
    "                    )\n",
    "                    print(\n",
    "                        dict(\n",
    "                            filename=file,\n",
    "                            article_idx=a + 1,\n",
    "                            per_article_cif_idx=per_article_cif_idx,\n",
    "                        )\n",
    "                    )\n",
    "\n",
    "                cifs[cif_name] = dict(\n",
    "                    structure=structure,\n",
    "                    shg=shg,\n",
    "                    filename=file,\n",
    "                    article_idx=a + 1,\n",
    "                    article_path=str(path),\n",
    "                    per_article_cif_idx=per_article_cif_idx,\n",
    "                )\n",
    "            except Exception:\n",
    "                skipped_other_reason += 1\n",
    "                traceback.print_exc()\n",
    "                pass\n",
    "        except Exception:\n",
    "            pass\n",
    "            traceback.print_exc()\n",
    "print(\n",
    "    f\"{(warnings_count,skipped_other_reason, skipped_sio2, len(cifs1), len(cifs2), len(cifs1) + len(cifs2))=}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print filename, d_kp\n",
    "for cif_name, v in cifs.items():\n",
    "    print(cif_name, v[\"filename\"], v[\"shg\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifs_shg_articles = {}\n",
    "\n",
    "for cif_name, v in cifs1.items():\n",
    "    cifs_shg_articles[cif_name.replace(\".cif\", \"\")] = v\n",
    "for cif_name, v in cifs2.items():\n",
    "    cifs_shg_articles[cif_name.replace(\".cif\", \"\")] = v\n",
    "# sorted(cifs1.keys()), sorted(cifs2.keys())\n",
    "sorted(cifs_shg_articles.keys()), len(cifs_shg_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_data_filename = \"../../raw_data/private/cifs_shg_articles_cor.json\"\n",
    "save_to_json(cifs_shg_articles, articles_data_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# articles_data_filename = \"../../raw_data/private/cifs_shg_articles.json\"\n",
    "# sg_articles = load_from_json(articles_data_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ABINIT data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# abinit json extraction from mpcontribs\n",
    "raw_abinit_filepath = \"../../raw_data/public/abinit.json\"\n",
    "\n",
    "\n",
    "def ab_extraction_from_mp_contribs(to_download: bool = False):\n",
    "    from mpcontribs.client import Client\n",
    "\n",
    "    MP_API_KEY = os.environ[\"MP_API_KEY\"]\n",
    "    client = Client(apikey=MP_API_KEY, project=\"shg\")\n",
    "    # print(client.available_query_params())\n",
    "    # print(client.query_projects())\n",
    "    d = client.get_all_ids()[\"shg\"]\n",
    "    keys = list(d.keys())\n",
    "    keys, len(d[keys[1]]), list(d[keys[0]])[0]\n",
    "    # print(client.get_contribution(\"654b3c3cad105cb1f2de5230\"))\n",
    "    data = {}\n",
    "    i = 0\n",
    "    if to_download:\n",
    "        for idx, ident in zip(d[keys[0]], d[keys[1]]):\n",
    "            contrib = client.get_contribution(idx)\n",
    "            data[idx] = dict(\n",
    "                data=contrib,\n",
    "                structure=client.get_structure(contrib[\"structures\"][0][\"id\"]),\n",
    "            )\n",
    "            i += 1\n",
    "            print(f\"{i=}\")\n",
    "    print(f\"{len(data)=}\")\n",
    "\n",
    "    data_json = {}\n",
    "    for k, v in data.items():\n",
    "        data_json[k] = dict(\n",
    "            data=v[\"data\"],\n",
    "            structure=v[\"structure\"].to_json(),\n",
    "        )\n",
    "    save_to_json(data_json, raw_abinit_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ab_extraction_from_mp_contribs(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_abinit_data_json = load_from_json(raw_abinit_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifs_shg_abinit = {}\n",
    "for cif_name, v in raw_abinit_data_json.items():\n",
    "    identifier = v[\"data\"][\"identifier\"]\n",
    "    # print(list(v[\"data\"].keys()))\n",
    "    # print(v[\"data\"][\"identifier\"])\n",
    "    cifs_shg_abinit[identifier] = {\n",
    "        \"data\": v[\"data\"],\n",
    "        \"structure\": Structure.from_str(v[\"structure\"], fmt=\"json\").as_dict(),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abinit_filepath = \"../../raw_data/public/shg_abinit.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_to_json(cifs_shg_abinit, abinit_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifs_shg_abinit = load_from_json(abinit_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create base_shg_eff_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run parse_shg and cmp_abinit_vs_amcm first\n",
    "# then run this cell\n",
    "# to get scalars from tensors\n",
    "raw_amcm_path = \"../../raw_data/private/am_cm/amcm.json\"\n",
    "# append to base\n",
    "base_shg_eff_dataset: dict[str, dict] = {}\n",
    "cifs_shg_amcm: dict = load_from_json(raw_amcm_path)\n",
    "m = 0\n",
    "for cif_name, v in cifs_shg_amcm.items():\n",
    "    # print(list(v[\"data\"][\"data\"][\"dinf\"].keys()))\n",
    "    shg = tensor2scalar(dict2tensor(v[\"data\"][\"data\"]))\n",
    "\n",
    "    print(cif_name)\n",
    "    try:\n",
    "        if shg < 250:\n",
    "            base_shg_eff_dataset[cif_name] = dict(\n",
    "                structure=v[\"structure\"],\n",
    "                shg=shg,\n",
    "            )\n",
    "            m = max(m, shg)\n",
    "        else:\n",
    "            print(\"filtered:\", cif_name)\n",
    "    except Exception:\n",
    "        print(cif_name, traceback.format_exc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename filenames in articles_data_filename like ccdc-*\n",
    "# and append to base\n",
    "cifs_shg_articles: dict = load_from_json(articles_data_filename)\n",
    "for cif_name, v in cifs_shg_articles.items():\n",
    "    print(\"ccdc-\" + cif_name)\n",
    "    if v[\"shg\"] is not None:\n",
    "        base_shg_eff_dataset[\"ccdc-\" + cif_name] = dict(\n",
    "            structure=v[\"structure\"], shg=v[\"shg\"]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get scalar shg from abinit\n",
    "# and append to base\n",
    "cifs_shg_abinit: dict = load_from_json(abinit_filepath)\n",
    "for cif_name, v in cifs_shg_abinit.items():\n",
    "    # print(list(v[\"data\"][\"data\"][\"dinf\"].keys()))\n",
    "    base_shg_eff_dataset[cif_name] = dict(\n",
    "        structure=v[\"structure\"],\n",
    "        shg=tensor2scalar(dict2tensor(v[\"data\"][\"data\"])),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_shg_eff_dataset if full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from base\n",
    "# filter cifs without specie\n",
    "for cif_name in list(base_shg_eff_dataset.keys()):\n",
    "    try:\n",
    "        crystal = Structure.from_dict(base_shg_eff_dataset[cif_name][\"structure\"])\n",
    "        [crystal[i].specie.number for i in range(len(crystal))]\n",
    "    except Exception as e:\n",
    "        base_shg_eff_dataset.pop(cif_name)\n",
    "        print(e, cif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter 'problematic' cifs\n",
    "# (they cannot be relabeled)\n",
    "import warnings\n",
    "\n",
    "for cif_name in list(base_shg_eff_dataset.keys()):\n",
    "    # warnings.filterwarnings(\"error\")\n",
    "    try:\n",
    "        with warnings.catch_warnings(record=True) as w:\n",
    "            warnings.simplefilter(\"always\")\n",
    "            crystal = Structure.from_dict(base_shg_eff_dataset[cif_name][\"structure\"])\n",
    "            crystal.relabel_sites(True).to_file(\"tmp_file.cif\", \"cif\")\n",
    "            crystal.from_file(\"tmp_file.cif\")\n",
    "            # print([e.category for e in w])\n",
    "            if len(w) == 3:\n",
    "                print(w[-1].message)\n",
    "            # assert len(w) == 1\n",
    "            # assert issubclass(w[-1].category, DeprecationWarning)\n",
    "            # assert \"deprecated\" in str(w[-1].message)\n",
    "\n",
    "    except Exception as e:\n",
    "        # if \"fractional coordinates rounded\" not in str(\n",
    "        #     e\n",
    "        # ) and \"We strongly discourage using implicit\" not in str(e):\n",
    "        base_shg_eff_dataset.pop(cif_name)\n",
    "        print(e, cif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_shg_eff_dataset_filepath = \"../../final_data/base_dataset_of_eff_shg.json\" - has problems with cifs_articles_data\n",
    "base_shg_eff_dataset_filepath = \"../../final_data/base_dataset_of_eff_shg_cor.json\" # fixed problems\n",
    "save_to_json(base_shg_eff_dataset, base_shg_eff_dataset_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_shg_eff_dataset: dict[str, dict] = load_from_json(base_shg_eff_dataset_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histogram by atom count\n",
    "atom_count = []\n",
    "for cif_name, v in base_shg_eff_dataset.items():\n",
    "    atom_count.append(len(Structure.from_dict(v[\"structure\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find potential repetitions by reduced form\n",
    "# (not removing anything)\n",
    "\n",
    "# check similar cifs to find the ones from different datasets\n",
    "# can the duplicate be present in one dataset? - yes, in icsd\n",
    "# Therefore, this code should be omitted\n",
    "\n",
    "# reduced_formula -> similar cif_names\n",
    "# reduced_formula_dict: dict[str, list[str]] = dict()\n",
    "# counter = 0\n",
    "# potential_repeat: list[tuple[list[str], str, str]] = []\n",
    "# for cif_name, v in base_shg_eff_dataset.items():\n",
    "#     # obtain reduced formula\n",
    "#     structure = Structure.from_dict(v[\"structure\"])\n",
    "#     reduced_formula = structure.reduced_formula\n",
    "#     # check if such reduced formula already present in dataset\n",
    "#     if reduced_formula in reduced_formula_dict:\n",
    "#         print(reduced_formula_dict[reduced_formula], cif_name, reduced_formula)\n",
    "#         counter += 1\n",
    "#         for potential_duplicate_cif_name in reduced_formula_dict[reduced_formula]:\n",
    "#             if potential_duplicate_cif_name.split(\"-\")[0] != cif_name.split(\"-\")[0]:\n",
    "#                 potential_repeat.append(\n",
    "#                     (reduced_formula_dict[reduced_formula], cif_name, reduced_formula)\n",
    "#                 )\n",
    "#                 break\n",
    "#     reduced_formula_dict.setdefault(reduced_formula, [])\n",
    "#     reduced_formula_dict[reduced_formula].append(cif_name)\n",
    "# print(\n",
    "#     counter,\n",
    "#     len(base_shg_eff_dataset),\n",
    "#     len(reduced_formula_dict),\n",
    "#     len(set(base_shg_eff_dataset.keys())),\n",
    "# )\n",
    "# potential_repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual check in MP (not removing anything)\n",
    "# for l, mp_id, c in potential_repeat:\n",
    "#     with MPRester(os.environ[\"MP_API_KEY\"]) as mpr:\n",
    "#         # gives deprecation warnings now\n",
    "#         # doc = mpr.materials.provenance.get_data_by_id(mp_id, fields=[\"database_IDs\"])\n",
    "#         # DeprecationWarning: get_data_by_id is deprecated and will be removed soon. Please use the search method instead.\n",
    "#         # if \"icsd\" in doc.database_IDs:\n",
    "#         #     print(doc.database_IDs[\"icsd\"])\n",
    "#         #     for icsd_id in l:\n",
    "#         #         if icsd_id in doc.database_IDs[\"icsd\"]:\n",
    "#         #             print(icsd_id, mp_id)\n",
    "#         # else:\n",
    "#         #     print(\"no icsd for\", mp_id)\n",
    "\n",
    "#         doc = mpr.materials.provenance.search(mp_id, fields=[\"database_IDs\"])\n",
    "#         # print(doc[0].database_IDs)\n",
    "#         if \"icsd\" in doc[0].database_IDs:\n",
    "#             print(doc[0].database_IDs[\"icsd\"])\n",
    "#             for icsd_id in l:\n",
    "#                 if icsd_id in doc[0].database_IDs[\"icsd\"]:\n",
    "#                     print(icsd_id, mp_id)\n",
    "#         else:\n",
    "#             print(\"no icsd for\", mp_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find structures with teh same reduced formulas\n",
    "reduced_formula_dict: dict[str, list[str]] = dict()\n",
    "for cif_name, v in base_shg_eff_dataset.items():\n",
    "    # obtain reduced formula\n",
    "    structure = Structure.from_dict(v[\"structure\"])\n",
    "    reduced_formula = structure.reduced_formula\n",
    "    reduced_formula_dict.setdefault(reduced_formula, [])\n",
    "    reduced_formula_dict[reduced_formula].append(cif_name)\n",
    "print(\n",
    "    len(base_shg_eff_dataset),\n",
    "    len(reduced_formula_dict),\n",
    "    len(set(base_shg_eff_dataset.keys())),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_struct(s:Structure, **kwargs):\n",
    "    atoms = s.to_ase_atoms()\n",
    "    write(\"tmp.png\", atoms, **kwargs)\n",
    "    plt.imshow(Image.open(\"tmp.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_same_struct(s1: Structure, s2: Structure, **kwargs):\n",
    "    matcher = StructureMatcher(**kwargs)\n",
    "    return matcher.fit(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicate based on reduced formula and then on structure matcher\n",
    "\n",
    "\n",
    "def get_dumplicates_by_structure_matcher(\n",
    "    is_same_struct_fn: Callable,\n",
    "    local_reduced_formula_dict: dict[str, list[str]] = reduced_formula_dict,\n",
    "    do_plots=False,\n",
    "):\n",
    "    # cif_id -> similarity group index (identity index)\n",
    "    cif2iid: dict[str, int] = {}\n",
    "    # identity index -> list[cif_ids]\n",
    "    iid2cifs: dict[int, list[str]] = {}\n",
    "    potential_duplicates = {}\n",
    "    iid_increment = 0\n",
    "    stats_total_steps = 0\n",
    "    for reduced_formula, similar_cifs in tqdm(local_reduced_formula_dict.items()):\n",
    "        if len(similar_cifs) > 1:\n",
    "            potential_duplicates.setdefault(reduced_formula, [])\n",
    "            potential_duplicates[reduced_formula].extend(similar_cifs)\n",
    "            print(f\"{reduced_formula=}\")\n",
    "            for pair in list(itertools.combinations(similar_cifs, 2)):\n",
    "                stats_total_steps += 1\n",
    "                cif_0 = pair[0]\n",
    "                cif_1 = pair[1]\n",
    "                structure0 = Structure.from_dict(\n",
    "                    base_shg_eff_dataset[cif_0][\"structure\"]\n",
    "                )\n",
    "                structure1 = Structure.from_dict(\n",
    "                    base_shg_eff_dataset[cif_1][\"structure\"]\n",
    "                )\n",
    "                if is_same_struct_fn(structure0, structure1):\n",
    "                    iid_increment += 1\n",
    "                    print(cif_0, \"=\", cif_1)\n",
    "                    print(structure0.formula, structure1.formula)\n",
    "                    if do_plots:\n",
    "                        plot_struct(structure0)\n",
    "                        plot_struct(structure1)\n",
    "                    # set equal identity idxes for two structures\n",
    "                    # and for all structures from the same identity groups\n",
    "                    minimal_iid = iid_increment\n",
    "                    relevant_iids: list[int] = [minimal_iid]\n",
    "                    if cif_0 in cif2iid:\n",
    "                        iid = cif2iid.get(cif_0, minimal_iid)\n",
    "                        relevant_iids.append(iid)\n",
    "                    if cif_1 in cif2iid:\n",
    "                        iid = cif2iid.get(cif_1, minimal_iid)\n",
    "                        relevant_iids.append(iid)\n",
    "                    relevant_iids = list(set(relevant_iids))\n",
    "                    minimal_iid = min(relevant_iids)\n",
    "                    merged_cifs = [cif_0, cif_1]\n",
    "                    # merge cifs from relevant iids to minimal_iid\n",
    "                    for iid in relevant_iids:\n",
    "                        if iid not in iid2cifs:\n",
    "                            continue\n",
    "                        for cif in iid2cifs[iid]:\n",
    "                            merged_cifs.append(cif)\n",
    "                            cif2iid[cif] = minimal_iid\n",
    "                        # remove cifs from old iid\n",
    "                        iid2cifs[iid] = []\n",
    "                    merged_cifs = list(set(merged_cifs))\n",
    "                    iid2cifs[minimal_iid] = merged_cifs\n",
    "                    cif2iid.setdefault(cif_0, minimal_iid)\n",
    "                    cif2iid.setdefault(cif_1, minimal_iid)\n",
    "                    iid_increment += 1\n",
    "                else:\n",
    "                    # assign new identity idxes in case of new structure\n",
    "                    # else pass\n",
    "                    cif2iid.setdefault(cif_0, iid_increment)\n",
    "                    cur_iid = cif2iid[cif_0]\n",
    "                    iid2cifs.setdefault(cur_iid, [])\n",
    "                    iid2cifs[cur_iid].append(cif_0)\n",
    "                    iid2cifs[cur_iid] = list(set(iid2cifs[cur_iid]))\n",
    "                    if cur_iid == iid_increment:\n",
    "                        iid_increment += 1\n",
    "\n",
    "                    # assign new identity idxes in case of new structure\n",
    "                    # else pass\n",
    "                    cif2iid.setdefault(cif_1, iid_increment)\n",
    "                    cur_iid = cif2iid[cif_1]\n",
    "                    iid2cifs.setdefault(cur_iid, [])\n",
    "                    iid2cifs[cur_iid].append(cif_1)\n",
    "                    iid2cifs[cur_iid] = list(set(iid2cifs[cur_iid]))\n",
    "                    if cur_iid == iid_increment:\n",
    "                        iid_increment += 1\n",
    "\n",
    "                    print(cif_0, \"!=\", cif_1)\n",
    "                    print(structure0.formula, structure1.formula)\n",
    "                    if do_plots:\n",
    "                        plot_struct(structure0)\n",
    "                        plot_struct(structure1)\n",
    "            # for cif_id in similar_cif_ids:\n",
    "    return cif2iid, iid2cifs, potential_duplicates, stats_total_steps\n",
    "\n",
    "\n",
    "cif2iid, iid2cifs, potential_duplicates, stats_total_steps = (\n",
    "    get_dumplicates_by_structure_matcher(is_same_struct)\n",
    ")\n",
    "stats_total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(potential_duplicates)=}\")\n",
    "print(f\"{sum([len(v) for k,v in potential_duplicates.items()])=}\")\n",
    "potential_duplicates_list = sorted([v for v in potential_duplicates.values()])\n",
    "potential_duplicates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates = {k: v for k, v in iid2cifs.items() if len(v) > 1}\n",
    "print(f\"{len(duplicates)=}\")\n",
    "print(f\"{sum([len(v) for k,v in duplicates.items()])=}\")\n",
    "duplicates_list = sorted([v for v in duplicates.values()])\n",
    "duplicates_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example from https://docs.materialsproject.org/methodology/materials-methodology/related-materials\n",
    "# which separates mp-561224 and mp-2739 successfully\n",
    "\n",
    "import numpy as np\n",
    "from mp_api.client import MPRester\n",
    "from matminer.featurizers.site import CrystalNNFingerprint\n",
    "from matminer.featurizers.structure import SiteStatsFingerprint\n",
    "import os\n",
    "MP_API_KEY = os.environ[\"MP_API_KEY\"]\n",
    "\n",
    "with MPRester(MP_API_KEY) as mpr:\n",
    "\n",
    "    # Get structures\n",
    "    diamond = mpr.get_structure_by_material_id(\"mp-66\")\n",
    "    gaas = mpr.get_structure_by_material_id(\"mp-2534\")\n",
    "    rocksalt = mpr.get_structure_by_material_id(\"mp-22862\")\n",
    "    perovskite = mpr.get_structure_by_material_id(\"mp-5827\")\n",
    "    spinel_caco2s4 = mpr.get_structure_by_material_id(\"mp-1408976\")\n",
    "    spinel_sicd2O4 = mpr.get_structure_by_material_id(\"mp-560842\")\n",
    "    tio2_1 = mpr.get_structure_by_material_id(\"mp-2739\")\n",
    "    tio2_2 = mpr.get_structure_by_material_id(\"mp-561224\")\n",
    "\n",
    "# Calculate structure fingerprints\n",
    "ssf = SiteStatsFingerprint(\n",
    "    CrystalNNFingerprint.from_preset('ops', distance_cutoffs=None, x_diff_weight=0),\n",
    "    stats=('mean', 'std_dev', 'minimum', 'maximum'))\n",
    "v_diamond = np.array(ssf.featurize(diamond))\n",
    "v_gaas = np.array(ssf.featurize(gaas))\n",
    "v_rocksalt = np.array(ssf.featurize(rocksalt))\n",
    "v_perovskite = np.array(ssf.featurize(perovskite))\n",
    "v_spinel_caco2s4 = np.array(ssf.featurize(spinel_caco2s4))\n",
    "v_spinel_sicd2O4 = np.array(ssf.featurize(spinel_sicd2O4))\n",
    "\n",
    "# Print out distance between structures\n",
    "print('Distance between diamond and GaAs: {:.4f}'.format(np.linalg.norm(v_diamond - v_gaas)))\n",
    "print('Distance between diamond and rocksalt: {:.4f}'.format(np.linalg.norm(v_diamond - v_rocksalt)))\n",
    "print('Distance between diamond and perovskite: {:.4f}'.format(np.linalg.norm(v_diamond - v_perovskite)))\n",
    "print('Distance between rocksalt and perovskite: {:.4f}'.format(np.linalg.norm(v_rocksalt - v_perovskite)))\n",
    "print('Distance between Ca(CoS2)2-spinel and Si(CdO2)2-spinel: {:.4f}'.format(np.linalg.norm(v_spinel_caco2s4 - v_spinel_sicd2O4)))\n",
    "# print(is_same_struct(diamond,gaas))\n",
    "# print(is_same_struct(tio2_1,tio2_2))\n",
    "print(np.exp(-np.linalg.norm(np.array(ssf.featurize(tio2_1)) - np.array(ssf.featurize(tio2_2)))) * 100)\n",
    "# Print out structure similarity percentages\n",
    "print('Diamond and GaAs Similarity: {:.2f}%'.format(np.exp(-np.linalg.norm(v_diamond - v_gaas)) * 100)) # = 100% for some reason\n",
    "print('Diamond and rocksalt Similarity: {:.2f}%'.format(np.exp(-np.linalg.norm(v_diamond - v_rocksalt)) * 100))\n",
    "print('Diamond and perovskite Similarity: {:.2f}%'.format(np.exp(-np.linalg.norm(v_diamond - v_perovskite)) * 100))\n",
    "print('Rocksalt and perovskite Similarity: {:.2f}%'.format(np.exp(-np.linalg.norm(v_rocksalt - v_perovskite)) * 100))\n",
    "print('Ca(CoS2)2-spinel and Si(CdO2)2-spinel Similarity: {:.2f}%'.format(np.exp(-np.linalg.norm(v_spinel_caco2s4 - v_spinel_sicd2O4)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = Structure.from_dict(base_shg_eff_dataset[\"icsd-9290\"][\"structure\"])\n",
    "# b = Structure.from_dict(base_shg_eff_dataset[\"icsd-193973\"][\"structure\"])\n",
    "# print(\n",
    "#     np.exp(-np.linalg.norm(np.array(ssf.featurize(a)) - np.array(ssf.featurize(b))))\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# from nvcs import viewer\n",
    "# view = viewer(tio2_2)\n",
    "# image = view.render_image()\n",
    "# view2 = viewer(tio2_1)\n",
    "# image_2 = view2.render_image()\n",
    "# view2 = viewer(tio2_1)\n",
    "# image_2 = view2.render_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# example \n",
    "\n",
    "# atoms = tio2_2.to_ase_atoms()\n",
    "# view(atoms)\n",
    "# write(\"tmp.png\", atoms)\n",
    "# write(\"tmp.png\", atoms, rotation=(\"0x,0y,0z\"))\n",
    "# # write(\"tmp.png\", atoms, radii=0.5, rotation=(\"0x,0y,0z\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_plots = False\n",
    "for identity_id, t in duplicates.items():\n",
    "    print(f\"{identity_id=}\")\n",
    "    imgs_list = []\n",
    "    for position, cif in enumerate(t):\n",
    "        s = Structure.from_dict(base_shg_eff_dataset[cif][\"structure\"])\n",
    "        atoms = s.to_ase_atoms()\n",
    "        write(\"tmp.png\", atoms, radii=0.5)\n",
    "        print(f\"{cif=}\")\n",
    "        img = Image.open(\"tmp.png\")\n",
    "        imgs_list.append(np.array(img))\n",
    "        if do_plots:\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "    if len(t) > 1:\n",
    "        for position, cif in enumerate(t[1:]):\n",
    "            # check equality of plots\n",
    "            if imgs_list[position - 1].shape == imgs_list[position].shape:\n",
    "                img_diff = np.max(np.abs(imgs_list[position] - imgs_list[position - 1]))\n",
    "                print(f\"{img_diff=}\")\n",
    "                print(f\"{img_diff > 0=}\")\n",
    "            else:\n",
    "                img_diff = \"high\"\n",
    "                print(f\"{img_diff=}\")\n",
    "                img_diff = 1\n",
    "                print(f\"{img_diff > 0=}\")\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_reduced_formula_dict = {\n",
    "    Structure.from_dict(\n",
    "        base_shg_eff_dataset[cif_list[0]][\"structure\"]\n",
    "    ).reduced_formula: cif_list\n",
    "    for cif_list in duplicates.values()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smaller_reduced_formula_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check duplicate based on reduced formula and then on structure matcher with CrystalNNFingerprint\n",
    "# redefine similarity function\n",
    "def is_same_struct_slow(s1: Structure, s2: Structure, **kwargs):\n",
    "    matcher = StructureMatcher(**kwargs)\n",
    "    is_same_based_on_crystal_fingerprint = (\n",
    "        np.exp(\n",
    "            -np.linalg.norm(np.array(ssf.featurize(s1)) - np.array(ssf.featurize(s2)))\n",
    "        )\n",
    "        > 0.999999999\n",
    "    )\n",
    "\n",
    "    return matcher.fit(s1, s2) and is_same_based_on_crystal_fingerprint\n",
    "\n",
    "\n",
    "cif2iid_smol, iid2cifs_smol, potential_duplicates_smol, stats_total_steps = (\n",
    "    get_dumplicates_by_structure_matcher(\n",
    "        is_same_struct_slow, smaller_reduced_formula_dict, do_plots=False\n",
    "    )\n",
    ")\n",
    "stats_total_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(potential_duplicates_smol)=}\")\n",
    "print(f\"{sum([len(v) for k,v in potential_duplicates_smol.items()])=}\")\n",
    "potential_duplicates_list_smol = sorted([v for v in potential_duplicates_smol.values()])\n",
    "potential_duplicates_list_smol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates_smol = {k: v for k, v in iid2cifs_smol.items() if len(v) > 1}\n",
    "print(f\"{len(duplicates_smol)=}\")\n",
    "print(f\"{sum([len(v) for k,v in duplicates_smol.items()])=}\")\n",
    "duplicates_list_smol = sorted([v for v in duplicates_smol.values()])\n",
    "duplicates_list_smol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_plots = True\n",
    "for identity_id, t in duplicates_smol.items():\n",
    "    print(f\"{identity_id=}\")\n",
    "    imgs_list = []\n",
    "    for position, cif in enumerate(t):\n",
    "        s = Structure.from_dict(base_shg_eff_dataset[cif][\"structure\"])\n",
    "        atoms = s.to_ase_atoms()\n",
    "        write(\"tmp.png\", atoms, radii=0.5)\n",
    "        shg = base_shg_eff_dataset[cif][\"shg\"]\n",
    "        print(f\"{cif=}, {shg=}\")\n",
    "        img = Image.open(\"tmp.png\")\n",
    "        imgs_list.append(np.array(img))\n",
    "        if do_plots:\n",
    "            plt.imshow(img)\n",
    "            plt.show()\n",
    "    if len(t) > 1:\n",
    "        for position, cif in enumerate(t[1:]):\n",
    "            # check equality of plots\n",
    "            if imgs_list[position - 1].shape == imgs_list[position].shape:\n",
    "                img_diff = np.max(np.abs(imgs_list[position] - imgs_list[position - 1]))\n",
    "                print(f\"{img_diff=}\")\n",
    "                print(f\"{img_diff > 0=}\")\n",
    "            else:\n",
    "                img_diff = \"high\"\n",
    "                print(f\"{img_diff=}\")\n",
    "                img_diff = 1\n",
    "                print(f\"{img_diff > 0=}\")\n",
    "    print(\"---------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual check\n",
    "s1 = Structure.from_dict(base_shg_eff_dataset[\"icsd-65763\"][\"structure\"])\n",
    "s2 = Structure.from_dict(base_shg_eff_dataset[\"icsd-171421\"][\"structure\"])\n",
    "\n",
    "is_same_struct(s1, s2), is_same_struct_slow(s1, s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(atom_count, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_line = True\n",
    "atom_count_ccdc = []\n",
    "atom_count_icsd = []\n",
    "atom_count_mp = []\n",
    "for cif_name, v in base_shg_eff_dataset.items():\n",
    "    if \"icsd\" in cif_name:\n",
    "        atom_count_icsd.append(len(Structure.from_dict(v[\"structure\"])))\n",
    "    if \"ccdc\" in cif_name:\n",
    "        atom_count_ccdc.append(len(Structure.from_dict(v[\"structure\"])))\n",
    "    if \"mp\" in cif_name:\n",
    "        atom_count_mp.append(len(Structure.from_dict(v[\"structure\"])))\n",
    "\n",
    "bins = np.linspace(0, 1200, 100)\n",
    "\n",
    "n, x, _ = plt.hist(\n",
    "    atom_count_ccdc,\n",
    "    bins=bins,\n",
    "    alpha=0.5,\n",
    "    fc=colors[0],\n",
    ")\n",
    "if draw_line:\n",
    "    plt.plot((x[1:] + x[:-1]) / 2, n, label=\"atom_count_ccdc\", c=colors[0])\n",
    "\n",
    "\n",
    "n, x, _ = plt.hist(\n",
    "    atom_count_icsd,\n",
    "    bins=bins,\n",
    "    alpha=0.5,\n",
    "    fc=colors[1],\n",
    ")\n",
    "if draw_line:\n",
    "    plt.plot((x[1:] + x[:-1]) / 2, n, label=\"atom_count_icsd\", c=colors[1])\n",
    "\n",
    "\n",
    "n, x, _ = plt.hist(\n",
    "    atom_count_mp,\n",
    "    bins=bins,\n",
    "    alpha=0.5,\n",
    "    fc=colors[2],\n",
    ")\n",
    "if draw_line:\n",
    "    plt.plot((x[1:] + x[:-1]) / 2, n, label=\"atom_count_mp\", c=colors[2])\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.show()\n",
    "len(atom_count_ccdc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(atom_count, bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cif_name, v in base_shg_eff_dataset.items():\n",
    "    print(cif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "big_crystals_threshold = 1000\n",
    "\n",
    "for cif_name, v in base_shg_eff_dataset.items():\n",
    "    if len(Structure.from_dict(v[\"structure\"])) > big_crystals_threshold:\n",
    "        print(cif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cif_name in list(base_shg_eff_dataset.keys()):\n",
    "    if (\n",
    "        len(Structure.from_dict(base_shg_eff_dataset[cif_name][\"structure\"]))\n",
    "        > big_crystals_threshold\n",
    "    ):\n",
    "        base_shg_eff_dataset.pop(cif_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_shg_eff_dataset_filepath = \"../../final_data/base_dataset_of_eff_shg.json\"\n",
    "dataset_base_plus_part_of_QMOF_dataset_filepath = (\n",
    "    \"../../final_data/dataset_base_plus_part_of_QMOF.json\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_to_json(base_shg_eff_dataset, base_shg_eff_dataset_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_shg_eff_dataset = load_from_json(base_shg_eff_dataset_filepath)\n",
    "dataset_base_plus_part_of_QMOF_dataset = load_from_json(\n",
    "    dataset_base_plus_part_of_QMOF_dataset_filepath\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets_list = [v[\"shg\"] for v in base_shg_eff_dataset.values()]\n",
    "targets_list = [v[\"shg\"] for v in dataset_base_plus_part_of_QMOF_dataset.values()]\n",
    "\n",
    "# plt.title(\"shg_eff hist for base dataset\")\n",
    "plt.title(\"d_KP distribution\")\n",
    "plt.hist(targets_list, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_line = True\n",
    "target_ccdc = []\n",
    "target_icsd = []\n",
    "target_mp = []\n",
    "target_qmof = []\n",
    "# for k, v in base_shg_eff_dataset.items():\n",
    "for cif_name, v in dataset_base_plus_part_of_QMOF_dataset.items():\n",
    "    if \"icsd\" in cif_name:\n",
    "        target_icsd.append(v[\"shg\"])\n",
    "    if \"ccdc\" in cif_name:\n",
    "        target_ccdc.append(v[\"shg\"])\n",
    "    if \"mp\" in cif_name:\n",
    "        target_mp.append(v[\"shg\"])\n",
    "    if \"qmof\" in cif_name:\n",
    "        target_qmof.append(v[\"shg\"])\n",
    "bins = np.linspace(0, 200, 100)\n",
    "\n",
    "n, x, _ = plt.hist(\n",
    "    target_ccdc,\n",
    "    bins=bins,\n",
    "    alpha=0.5,\n",
    "    fc=colors[0],\n",
    ")\n",
    "if draw_line:\n",
    "    plt.plot((x[1:] + x[:-1]) / 2, n, label=\"CCDC\", c=colors[0])\n",
    "\n",
    "\n",
    "n, x, _ = plt.hist(\n",
    "    target_icsd,\n",
    "    bins=bins,\n",
    "    alpha=0.5,\n",
    "    fc=colors[1],\n",
    ")\n",
    "if draw_line:\n",
    "    plt.plot((x[1:] + x[:-1]) / 2, n, label=\"ICSD\", c=colors[1])\n",
    "\n",
    "\n",
    "n, x, _ = plt.hist(\n",
    "    target_mp,\n",
    "    bins=bins,\n",
    "    alpha=0.5,\n",
    "    fc=colors[2],\n",
    ")\n",
    "if draw_line:\n",
    "    plt.plot((x[1:] + x[:-1]) / 2, n, label=\"MP\", c=colors[2])\n",
    "\n",
    "n, x, _ = plt.hist(\n",
    "    target_qmof,\n",
    "    bins=bins,\n",
    "    alpha=0.5,\n",
    "    fc=colors[3],\n",
    ")\n",
    "if draw_line:\n",
    "    plt.plot((x[1:] + x[:-1]) / 2, n, label=\"QMOF\", c=colors[3])\n",
    "\n",
    "plt.xlabel(\"$d_{KP}$, pm/V\")\n",
    "plt.ylabel(\"count\")\n",
    "plt.legend()\n",
    "plt.title(\"$d_{KP}$ distribution\")\n",
    "plt.yscale(\"log\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_properties = dict(\n",
    "    mean=np.mean(targets_list), median=np.median(targets_list), std=np.std(targets_list)\n",
    ")\n",
    "targets_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.experiment_tracking import calculate_metrics\n",
    "\n",
    "\n",
    "print(\n",
    "    \"mean\",\n",
    "    calculate_metrics(targets_list, np.ones_like(targets_list) * np.mean(targets_list)),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"median\",\n",
    "    calculate_metrics(\n",
    "        targets_list, np.ones_like(targets_list) * np.median(targets_list)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cifs_shg_abinit: dict = load_from_json(abinit_filepath)\n",
    "base_max_abs_shg_dataset = {}\n",
    "for cif_name, v in cifs_shg_abinit.items():\n",
    "    # print(list(v[\"data\"][\"data\"][\"dinf\"].keys()))\n",
    "    base_max_abs_shg_dataset[cif_name] = dict(\n",
    "        structure=v[\"structure\"],\n",
    "        shg=np.max(np.abs(dict2tensor(v[\"data\"][\"data\"]))),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run parse_shg and cmp_abinit_vs_amcm first\n",
    "cifs_shg_amcm: dict = load_from_json(\"../../raw_data/private/am_cm/amcm.json\")\n",
    "m = 0\n",
    "for cif_name, v in cifs_shg_amcm.items():\n",
    "    # print(list(v[\"data\"][\"data\"][\"dinf\"].keys()))\n",
    "    shg = np.max(np.abs(dict2tensor(v[\"data\"][\"data\"])))\n",
    "\n",
    "    print(cif_name)\n",
    "    try:\n",
    "        if shg < 250:\n",
    "            base_max_abs_shg_dataset[cif_name] = dict(\n",
    "                structure=v[\"structure\"],\n",
    "                shg=shg,\n",
    "            )\n",
    "            m = max(m, shg)\n",
    "    except Exception as e:\n",
    "        print(cif_name, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_line = True\n",
    "target_ccdc = []\n",
    "target_icsd = []\n",
    "target_mp = []\n",
    "for cif_name, v in base_max_abs_shg_dataset.items():\n",
    "    if \"icsd\" in cif_name:\n",
    "        target_icsd.append(v[\"shg\"])\n",
    "    if \"ccdc\" in cif_name:\n",
    "        target_ccdc.append(v[\"shg\"])\n",
    "    if \"mp\" in cif_name:\n",
    "        target_mp.append(v[\"shg\"])\n",
    "\n",
    "bins = np.linspace(0, 200, 100)\n",
    "\n",
    "n, x, _ = plt.hist(\n",
    "    target_ccdc,\n",
    "    bins=bins,\n",
    "    alpha=0.5,\n",
    "    fc=colors[0],\n",
    ")\n",
    "if draw_line:\n",
    "    plt.plot((x[1:] + x[:-1]) / 2, n, label=\"target_ccdc\", c=colors[0])\n",
    "\n",
    "\n",
    "n, x, _ = plt.hist(\n",
    "    target_icsd,\n",
    "    bins=bins,\n",
    "    alpha=0.5,\n",
    "    fc=colors[1],\n",
    ")\n",
    "if draw_line:\n",
    "    plt.plot((x[1:] + x[:-1]) / 2, n, label=\"target_icsd\", c=colors[1])\n",
    "\n",
    "\n",
    "n, x, _ = plt.hist(\n",
    "    target_mp,\n",
    "    bins=bins,\n",
    "    alpha=0.5,\n",
    "    fc=colors[2],\n",
    ")\n",
    "if draw_line:\n",
    "    plt.plot((x[1:] + x[:-1]) / 2, n, label=\"target_mp\", c=colors[2])\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"shg_max_abs hist for base_max_abs_shg_dataset\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_list = [v[\"shg\"] for v in base_max_abs_shg_dataset.values()]\n",
    "\n",
    "print(\n",
    "    \"mean\",\n",
    "    calculate_metrics(targets_list, np.ones_like(targets_list) * np.mean(targets_list)),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"median\",\n",
    "    calculate_metrics(\n",
    "        targets_list, np.ones_like(targets_list) * np.median(targets_list)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "data = np.abs(targets_list) + 1e-100\n",
    "\n",
    "transformed_data, lambda_value = stats.boxcox(data)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data, bins=10, density=True, alpha=0.6, color=\"blue\", edgecolor=\"black\")\n",
    "plt.title(\"Original Data Density\")\n",
    "plt.xlabel(\"Values\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(\n",
    "    transformed_data,\n",
    "    bins=10,\n",
    "    density=True,\n",
    "    alpha=0.6,\n",
    "    color=\"orange\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "plt.title(\"Box-Cox Transformed Data Density\")\n",
    "plt.xlabel(\"Values\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Lambda value for Box-Cox transformation: {lambda_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_abs_shg_dataset = load_from_json(\"../../final_data/dataset_of_max_abs_shg.json\")\n",
    "targets_list = [v[\"shg\"] for v in max_abs_shg_dataset.values()]\n",
    "\n",
    "print(\n",
    "    \"mean\",\n",
    "    calculate_metrics(targets_list, np.ones_like(targets_list) * np.mean(targets_list)),\n",
    ")\n",
    "\n",
    "print(\n",
    "    \"median\",\n",
    "    calculate_metrics(\n",
    "        targets_list, np.ones_like(targets_list) * np.median(targets_list)\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "\n",
    "data = np.abs(targets_list) + 1e-100\n",
    "\n",
    "transformed_data, lambda_value = stats.boxcox(data)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(data, bins=10, density=True, alpha=0.6, color=\"blue\", edgecolor=\"black\")\n",
    "plt.title(\"Original Data Density\")\n",
    "plt.xlabel(\"Values\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(\n",
    "    transformed_data,\n",
    "    bins=10,\n",
    "    density=True,\n",
    "    alpha=0.6,\n",
    "    color=\"orange\",\n",
    "    edgecolor=\"black\",\n",
    ")\n",
    "plt.title(\"Box-Cox Transformed Data Density\")\n",
    "plt.xlabel(\"Values\")\n",
    "plt.ylabel(\"Density\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Lambda value for Box-Cox transformation: {lambda_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cgcnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
